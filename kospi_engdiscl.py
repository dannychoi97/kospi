import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import time
import random

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì½”ìŠ¤í”¼ ì˜ë¬¸ê³µì‹œ í•„í„°ë§ ë„êµ¬", layout="wide")

st.title('ğŸ¯ ì˜¤ëŠ˜ì˜ ì½”ìŠ¤í”¼ ë²ˆì—­ëŒ€ìƒ ê³µì‹œ')
st.markdown("---")

# --- [ìˆ˜ì •] ì‚¬ì´ë“œë°” ê³µì§€ì‚¬í•­ (ì£¼ëª©ë„ ì—…ê·¸ë ˆì´ë“œ) ---
with st.sidebar:
    st.markdown("## ğŸš¨ ì¤‘ìš” ê³µì§€")
    st.warning(
        """
        **ë³¸ ì‚¬ì´íŠ¸ëŠ” ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ë¯€ë¡œ, íŠ¸ë˜í”½ ì§‘ì¤‘ ì‹œ ì™¸ë¶€ ì„œë²„ë¡œë¶€í„° ì¼ì‹œì  ì°¨ë‹¨ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.** ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ì´ìš©ì„ ìœ„í•´ **ì´ 3ê°œì˜ ì‚¬ì´íŠ¸**ë¥¼ ìš´ì˜ ì¤‘ì´ë‹ˆ, ì¥ì•  ë°œìƒ ì‹œ ë‹¤ë¥¸ ì£¼ì†Œë¡œ ì ‘ì†í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.
        
        ---
        **ğŸ”— ì´ìš© ê°€ëŠ¥í•œ ì‚¬ì´íŠ¸ ëª©ë¡**
        1. https://englishkind.streamlit.app/
        2. https://english-kospi.streamlit.app/
        3. https://englishkospi.streamlit.app/
        """
    )
    st.markdown("---")
    
# 2. ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
@st.cache_data
def load_reference_data():
    try:
        # íŒŒì¼ ê²½ë¡œê°€ ì •í™•í•œì§€ í™•ì¸ í•„ìš”
        df_svc = pd.read_csv("kospi_format.csv", dtype=str)
        df_listed = pd.read_csv("kospi_company.csv", dtype=str)
        if not df_listed.empty and 'íšŒì‚¬ì½”ë“œ' in df_listed.columns:
            df_listed['íšŒì‚¬ì½”ë“œ'] = df_listed['íšŒì‚¬ì½”ë“œ'].astype(str).str.zfill(6) # 5ìë¦¬ì—ì„œ 6ìë¦¬ë¡œ ìˆ˜ì • (ì¢…ëª©ì½”ë“œëŠ” ë³´í†µ 6ìë¦¬)
        return df_svc, df_listed
    except Exception as e:
        st.error(f"âš ï¸ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame(), pd.DataFrame()

df_svc, df_listed = load_reference_data()

# 3. ë‚ ì§œ ì„¤ì •
selected_date = st.date_input("ğŸ“… ì¡°íšŒì¼ì ì„ íƒ", value=datetime.today())
today_str = selected_date.strftime("%Y-%m-%d")

# 4. í¬ë¡¤ë§ ì—”ì§„ ìˆ˜ì •
def get_all_kind_data(date_str):
    main_url = "https://kind.krx.co.kr/disclosure/todaydisclosure.do"
    ajax_url = "https://kind.krx.co.kr/disclosure/todaydisclosure.do"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Referer": main_url,
        "X-Requested-With": "XMLHttpRequest"
    }

    session = requests.Session()
    all_rows = []
    
    try:
        session.get(main_url, headers=headers)
        
        # ì²« ë²ˆì§¸ ìš”ì²­: ì „ì²´ ê±´ìˆ˜ì™€ í˜ì´ì§€ ìˆ˜ íŒŒì•…
        payload = {
            "method": "searchTodayDisclosureSub",
            "currentPageSize": 100,
            "pageIndex": 1,
            "orderMode": "0", # 0: ì‹œê°„ìˆœ
            "orderStat": "A", # D: ë‚´ë¦¼ì°¨ìˆœ(ìµœì‹ ìˆœ), A: ì˜¤ë¦„ì°¨ìˆœ(ê³¼ê±°ìˆœ) -> ì˜¤ì „ ë°ì´í„°ë¶€í„° ê°€ì ¸ì˜¤ë„ë¡ Aë¡œ ë³€ê²½ ì‹œë„ ê°€ëŠ¥
            "forward": "todaydisclosure_sub",
            "marketType": "1", # ì½”ìŠ¤í”¼
            "selDate": date_str
        }
        
        first_resp = session.post(ajax_url, data=payload, headers=headers)
        soup = BeautifulSoup(first_resp.text, 'html.parser')
        
        # ì „ì²´ í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ ë³´ê°•
        info_text = soup.select_one('.info.type-00')
        total_pages = 1
        if info_text:
            # " [ 1 / 3 í˜ì´ì§€ ] " í˜•íƒœì—ì„œ ìˆ«ì ì¶”ì¶œ
            page_match = re.search(r'/(\d+)', info_text.text)
            if page_match:
                total_pages = int(page_match.group(1))
        
        progress_text = st.empty()
        progress_bar = st.progress(0)

        for page in range(1, total_pages + 1):
            progress_text.text(f"â³ {total_pages}í˜ì´ì§€ ì¤‘ {page}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
            payload["pageIndex"] = page
            resp = session.post(ajax_url, data=payload, headers=headers)
            p_soup = BeautifulSoup(resp.text, 'html.parser')
            
            table = p_soup.find('table', class_='list type-00 mt10')
            if not table: continue
            
            rows = table.find('tbody').find_all('tr')
            for tr in rows:
                tds = tr.find_all('td')
                if len(tds) < 5 or "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in tr.text: continue
                
                # íšŒì‚¬ì½”ë“œ ì¶”ì¶œ
                comp_a = tds[1].find('a')
                comp_code = ""
                if comp_a and comp_a.has_attr('onclick'):
                    code_match = re.search(r"companysummary_open\('(\d+)'\)", comp_a['onclick'])
                    if code_match: comp_code = code_match.group(1).zfill(6)
                
                # ì œëª© ë° ì ‘ìˆ˜ë²ˆí˜¸
                title_a = tds[2].find('a')
                title = title_a.get('title', '').strip() if title_a else tds[2].text.strip()
                acpt_no = ""
                if title_a and title_a.has_attr('onclick'):
                    no_match = re.search(r"openDisclsViewer\('(\d+)'", title_a['onclick'])
                    if no_match: acpt_no = no_match.group(1)
                
                all_rows.append({
                    'ì‹œê°„': tds[0].text.strip(),
                    'íšŒì‚¬ì½”ë“œ': comp_code,
                    'íšŒì‚¬ëª…': tds[1].text.strip(),
                    'ê³µì‹œì œëª©': title,
                    'ì œì¶œì¸': tds[3].text.strip(),
                    'ìƒì„¸URL': f"https://kind.krx.co.kr/common/disclsviewer.do?method=search&acptno={acpt_no}" if acpt_no else ""
                })
            
            progress_bar.progress(page / total_pages)
            time.sleep(random.uniform(0.3, 0.6)) # ì„œë²„ ë¶€í•˜ ë°©ì§€
            
        progress_text.empty()
        return pd.DataFrame(all_rows)

    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# 5. ì‹¤í–‰ ë° í•„í„°ë§
# ë²„íŠ¼ ëª…ì¹­ ë³€ê²½: 'ì½”ìŠ¤í”¼ ì˜ë¬¸ê³µì‹œ ì§€ì›ëŒ€ìƒ ê³µì‹œì¡°íšŒ'
if st.button('ğŸš€ ì½”ìŠ¤í”¼ ì˜ë¬¸ê³µì‹œ ì§€ì›ëŒ€ìƒ ê³µì‹œì¡°íšŒ'):
    if df_svc.empty or df_listed.empty:
        st.warning("ê¸°ì¤€ ë°ì´í„°(CSV)ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        with st.spinner(f'{today_str} ëª¨ë“  ê³µì‹œ í˜ì´ì§€ë¥¼ ì „ìˆ˜ ì¡°ì‚¬ ì¤‘ì…ë‹ˆë‹¤...'):
            df_raw = get_all_kind_data(today_str)
            
            if not df_raw.empty:
                # í•„í„°ë§ ë¡œì§
                target_forms = df_svc['ì„œì‹ëª…'].unique().tolist()
                target_codes = df_listed['íšŒì‚¬ì½”ë“œ'].tolist()

                def filter_logic(row):
                    title = row['ê³µì‹œì œëª©']
                    code = row['íšŒì‚¬ì½”ë“œ']
                    # ì œì™¸ ì¡°ê±´
                    if title.startswith(("ì¶”ê°€ìƒì¥", "ë³€ê²½ìƒì¥")): return False
                    # í¬í•¨ ì¡°ê±´ (ì„œì‹ëª… í¬í•¨ AND ì§€ì›ëŒ€ìƒ íšŒì‚¬ì½”ë“œ)
                    return any(f in title for f in target_forms) and (code in target_codes)

                final_df = df_raw[df_raw.apply(filter_logic, axis=1)]

                st.subheader(f"ğŸ“Š {today_str} ì „ì²´ ê³µì‹œ {len(df_raw)}ê±´ ì¤‘ í•„í„°ë§ ê²°ê³¼")
                if not final_df.empty:
                    # ì‹œê°„ìˆœìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ì •ë ¬ (ì˜¤ì „ -> ì˜¤í›„)
                    final_df = final_df.sort_values(by='ì‹œê°„')
                    st.dataframe(
                        final_df[['ì‹œê°„', 'íšŒì‚¬ëª…', 'ê³µì‹œì œëª©', 'ì œì¶œì¸', 'ìƒì„¸URL']],
                        column_config={"ìƒì„¸URL": st.column_config.LinkColumn("ê³µì‹œë³´ê¸°")},
                        hide_index=True, use_container_width=True
                    )
                else:
                    st.info("í•´ë‹¹ ë‚ ì§œì— ì¡°ê±´ì— ë§ëŠ” ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¥ ì‹œì‘ ì „ì´ê±°ë‚˜ ì ‘ê·¼ì´ ì¼ì‹œì ìœ¼ë¡œ ì°¨ë‹¨ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
