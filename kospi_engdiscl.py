import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta
import time
import random

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì½”ìŠ¤í”¼ ì˜ë¬¸ê³µì‹œ í•„í„°ë§ ë„êµ¬", layout="wide")

st.title('ğŸ¯ ì˜¤ëŠ˜ì˜ ì½”ìŠ¤í”¼ ë²ˆì—­ëŒ€ìƒ ê³µì‹œ ì¡°íšŒ')
st.markdown("---")

# 2. ë°ì´í„° ë¡œë“œ (CSV)
@st.cache_data
def load_reference_data():
    try:
        # íŒŒì¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”
        df_svc = pd.read_csv("kospi_format.csv", dtype=str)
        df_listed = pd.read_csv("kospi_company.csv", dtype=str)
        
        # íšŒì‚¬ì½”ë“œ 5ìë¦¬ ìë¦¿ìˆ˜ ë§ì¶”ê¸° (00010 ë“±)
        if not df_listed.empty and 'íšŒì‚¬ì½”ë“œ' in df_listed.columns:
            df_listed['íšŒì‚¬ì½”ë“œ'] = df_listed['íšŒì‚¬ì½”ë“œ'].astype(str).str.zfill(5)
            
        return df_svc, df_listed
    except Exception as e:
        st.error(f"âš ï¸ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame(), pd.DataFrame()

df_svc, df_listed = load_reference_data()

# --- [ì¶”ê°€ëœ ë¶€ë¶„] ìƒë‹¨ ê¸°ì¤€ ë°ì´í„° í‘œì‹œ ë ˆì´ì•„ì›ƒ ---
if not df_svc.empty and not df_listed.empty:
    col_ref1, col_ref2 = st.columns(2)
    
    with col_ref1:
        st.subheader("ğŸ“‹ ì§€ì›ëŒ€ìƒ ê³µì‹œì„œì‹")
        st.caption(f"ì´ {len(df_svc)}ê°œì˜ ì„œì‹ì„ ë²ˆì—­ ì¤‘ì…ë‹ˆë‹¤.")
        st.dataframe(df_svc, use_container_width=True, height=200)
        
    with col_ref2:
        st.subheader("ğŸ¢ ì§€ì›ëŒ€ìƒ íšŒì‚¬ëª©ë¡")
        st.caption(f"ì´ {len(df_listed)}ê°œì˜ ìƒì¥ë²•ì¸ì´ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.dataframe(df_listed, use_container_width=True, height=200)
else:
    st.warning("âš ï¸ ê¸°ì¤€ ë°ì´í„°(CSV)ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

st.markdown("---")

# 3. ë‚ ì§œ ì„¤ì • ë° ì‚¬ìš©ì ì…ë ¥
selected_date = st.date_input("ğŸ“… ì¡°íšŒì¼ì ì„ íƒ", value=datetime.today())
today_str = selected_date.strftime("%Y-%m-%d")

# 4. í¬ë¡¤ë§ ì—”ì§„ (403 ë°©ì–´í˜•)
def get_kind_data(date_str):
    main_url = "https://kind.krx.co.kr/disclosure/todaydisclosure.do"
    ajax_url = "https://kind.krx.co.kr/disclosure/todaydisclosure.do"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Accept": "text/html, */*; q=0.01",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": "https://kind.krx.co.kr",
        "Referer": "https://kind.krx.co.kr/disclosure/todaydisclosure.do",
        "X-Requested-With": "XMLHttpRequest"
    }

    session = requests.Session()
    
    try:
        # Step 1: í†µí–‰ì¦(ì¿ í‚¤) íšë“
        session.get(main_url, headers=headers, timeout=10)
        time.sleep(random.uniform(0.3, 0.7))

        # Step 2: ë°ì´í„° ìš”ì²­
        payload = {
            "method": "searchTodayDisclosureSub",
            "currentPageSize": 100,
            "pageIndex": 1,
            "orderMode": "0",
            "orderStat": "D",
            "forward": "todaydisclosure_sub",
            "marketType": "1", # ì½”ìŠ¤í”¼
            "selDate": date_str
        }
        
        response = session.post(ajax_url, data=payload, headers=headers, timeout=10)
        response.raise_for_status()
        
        # Step 3: íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')
        rows = []
        table = soup.find('table', class_='list type-00 mt10')
        
        if not table: return pd.DataFrame()

        for tr in table.find('tbody').find_all('tr'):
            tds = tr.find_all('td')
            if len(tds) < 5 or "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in tr.text: continue
            
            # íšŒì‚¬ì½”ë“œ ì¶”ì¶œ
            comp_a = tds[1].find('a')
            comp_code = ""
            if comp_a and comp_a.has_attr('onclick'):
                code_match = re.search(r"companysummary_open\('(\d+)'\)", comp_a['onclick'])
                if code_match: comp_code = code_match.group(1)
            
            # ì œëª© ë° URL ì¶”ì¶œ
            title_a = tds[2].find('a')
            title = title_a.get('title', '').strip() if title_a else ""
            acpt_no = ""
            if title_a and title_a.has_attr('onclick'):
                no_match = re.search(r"openDisclsViewer\('(\d+)'", title_a['onclick'])
                if no_match: acpt_no = no_match.group(1)
            
            rows.append({
                'ì‹œê°„': tds[0].text.strip(),
                'íšŒì‚¬ì½”ë“œ': comp_code,
                'íšŒì‚¬ëª…': tds[1].text.strip(),
                'ê³µì‹œì œëª©': title,
                'ì œì¶œì¸': tds[3].text.strip(),
                'ìƒì„¸URL': f"https://kind.krx.co.kr/common/disclsviewer.do?method=search&acptno={acpt_no}" if acpt_no else ""
            })
            
        return pd.DataFrame(rows)

    except Exception as e:
        st.error(f"âŒ KIND ì„œë²„ ì ‘ì† ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# 5. ì‹¤í–‰ ë²„íŠ¼ ë° ê²°ê³¼ ì¶œë ¥
if st.button('ğŸš€ ì˜ë¬¸ê³µì‹œ ì§€ì›ëŒ€ìƒ í•„í„°ë§ ì‹¤í–‰'):
    if df_svc.empty or df_listed.empty:
        st.error("ê¸°ì¤€ ë°ì´í„°ê°€ ì—†ì–´ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        with st.spinner('ì‹¤ì‹œê°„ ê³µì‹œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            df_raw = get_kind_data(today_str)
            
            if df_raw.empty:
                st.info("ì¡°íšŒëœ ê³µì‹œê°€ ì—†ê±°ë‚˜ ì ‘ê·¼ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            else:
                # í•„í„°ë§
                target_forms = df_svc['ì„œì‹ëª…'].unique().tolist()
                target_codes = df_listed['íšŒì‚¬ì½”ë“œ'].tolist()

                def filter_logic(row):
                    title = row['ê³µì‹œì œëª©']
                    code = row['íšŒì‚¬ì½”ë“œ']
                    # ì œì™¸ í‚¤ì›Œë“œ
                    if title.startswith(("ì¶”ê°€ìƒì¥", "ë³€ê²½ìƒì¥")): return False
                    # ì„œì‹ëª… ë° íšŒì‚¬ì½”ë“œ ë§¤ì¹­
                    return any(f in title for f in target_forms) and (code in target_codes)

                final_df = df_raw[df_raw.apply(filter_logic, axis=1)]

                st.subheader(f"ğŸ“Š í•„í„°ë§ ê²°ê³¼ (ëŒ€ìƒ: {len(final_df)}ê±´)")
                if not final_df.empty:
                    st.dataframe(
                        final_df[['ì‹œê°„', 'íšŒì‚¬ëª…', 'ê³µì‹œì œëª©', 'ì œì¶œì¸', 'ìƒì„¸URL']],
                        column_config={"ìƒì„¸URL": st.column_config.LinkColumn("ê³µì‹œë³´ê¸°")},
                        hide_index=True,
                        use_container_width=True
                    )
                else:
                    st.info("ì˜¤ëŠ˜ í˜„ì¬ê¹Œì§€ ì§€ì› ëŒ€ìƒì— í•´ë‹¹í•˜ëŠ” ê³µì‹œëŠ” ì—†ìŠµë‹ˆë‹¤.")
